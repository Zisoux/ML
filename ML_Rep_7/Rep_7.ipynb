{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba010f6",
   "metadata": {},
   "source": [
    "## 데이터 수집 및 전처리..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier  # 사용 시 주석 해제\n",
    "\n",
    "# 1. 데이터 불러오기 및 라벨 추가\n",
    "walk_df = pd.read_csv(\"걷기데이터.csv\")\n",
    "walk_df[\"label\"] = \"walk\"\n",
    "\n",
    "run_df = pd.read_csv(\"뛰기데이터.csv\")\n",
    "run_df[\"label\"] = \"run\"\n",
    "\n",
    "stop_df = pd.read_csv(\"정지데이터.csv\")\n",
    "stop_df[\"label\"] = \"stop\"\n",
    "\n",
    "# 병합\n",
    "df = pd.concat([walk_df, run_df, stop_df], ignore_index=True)\n",
    "\n",
    "# 사용할 컬럼 지정\n",
    "feature_cols = [\n",
    "    'Linear Acceleration x (m/s^2)',\n",
    "    'Linear Acceleration y (m/s^2)',\n",
    "    'Linear Acceleration z (m/s^2)'\n",
    "]\n",
    "\n",
    "# 2. 전처리: 수치형 변환 → 결측치 제거 → 이상치 제거\n",
    "for col in feature_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df_clean = df.dropna(subset=feature_cols)\n",
    "z_scores = np.abs(zscore(df_clean[feature_cols]))\n",
    "df_clean = df_clean[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# 3. 시각화 (pairplot)\n",
    "sns.pairplot(df_clean[feature_cols + ['label']], hue='label', diag_kind=\"hist\")\n",
    "plt.suptitle(\"센서 데이터 상태별 분포 (전처리 후)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# 4. 학습 데이터 구성\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. 모델 정의 및 학습\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    # 'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')  # y를 숫자로 바꿔야 사용 가능\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='macro'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='macro'),\n",
    "        'F1 Score': f1_score(y_test, y_pred, average='macro')\n",
    "    })\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[\"walk\", \"run\", \"stop\"])\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=[\"walk\", \"run\", \"stop\"], yticklabels=[\"walk\", \"run\", \"stop\"])\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 6. 성능 비교표 출력\n",
    "results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)\n",
    "print(\"\\n📊 모델 성능 비교:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d97a3",
   "metadata": {},
   "source": [
    "## Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 페이지 설정\n",
    "st.set_page_config(page_title=\"Sensor Activity Classifier\", layout=\"wide\")\n",
    "st.title(\"📊 Sensor Activity Classification App\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "이 앱은 가속도 센서 데이터를 기반으로 사람의 상태 (걷기, 뛰기, 정지)를 예측하는 머신러닝 모델을 비교합니다.\n",
    "\"\"\")\n",
    "\n",
    "# 데이터 업로드\n",
    "uploaded_walk = st.file_uploader(\"걷기 데이터 업로드\", type=\"csv\")\n",
    "uploaded_run = st.file_uploader(\"뛰기 데이터 업로드\", type=\"csv\")\n",
    "uploaded_stop = st.file_uploader(\"정지 데이터 업로드\", type=\"csv\")\n",
    "\n",
    "if uploaded_walk and uploaded_run and uploaded_stop:\n",
    "    # CSV 읽기\n",
    "    walk_df = pd.read_csv(uploaded_walk)\n",
    "    walk_df['label'] = 'walk'\n",
    "    run_df = pd.read_csv(uploaded_run)\n",
    "    run_df['label'] = 'run'\n",
    "    stop_df = pd.read_csv(uploaded_stop)\n",
    "    stop_df['label'] = 'stop'\n",
    "\n",
    "    # 병합\n",
    "    df = pd.concat([walk_df, run_df, stop_df], ignore_index=True)\n",
    "\n",
    "    # 전처리\n",
    "    feature_cols = [\n",
    "        'Linear Acceleration x (m/s^2)',\n",
    "        'Linear Acceleration y (m/s^2)',\n",
    "        'Linear Acceleration z (m/s^2)'\n",
    "    ]\n",
    "    for col in feature_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    df = df.dropna(subset=feature_cols)\n",
    "\n",
    "    # 이상치 제거\n",
    "    from scipy.stats import zscore\n",
    "    z_scores = np.abs(zscore(df[feature_cols]))\n",
    "    df = df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "    # 시각화\n",
    "    st.subheader(\"📈 Feature Pairplot\")\n",
    "    fig = sns.pairplot(df[feature_cols + ['label']], hue='label', diag_kind=\"hist\")\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    # 학습 준비\n",
    "    X = df[feature_cols]\n",
    "    y = df['label']\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 모델\n",
    "    models = {\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    st.subheader(\"📊 Model Performance\")\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='macro')\n",
    "        rec = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "\n",
    "        st.markdown(f\"### {name} Confusion Matrix\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        fig_cm, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, ax=ax)\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"True\")\n",
    "        st.pyplot(fig_cm)\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)\n",
    "    st.subheader(\"🏁 Summary Table\")\n",
    "    st.dataframe(results_df, use_container_width=True)\n",
    "\n",
    "else:\n",
    "    st.info(\"모든 센서 CSV 파일(걷기, 뛰기, 정지)을 업로드해주세요.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
