{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba010f6",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier  # ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë¼ë²¨ ì¶”ê°€\n",
    "walk_df = pd.read_csv(\"ê±·ê¸°ë°ì´í„°.csv\")\n",
    "walk_df[\"label\"] = \"walk\"\n",
    "\n",
    "run_df = pd.read_csv(\"ë›°ê¸°ë°ì´í„°.csv\")\n",
    "run_df[\"label\"] = \"run\"\n",
    "\n",
    "stop_df = pd.read_csv(\"ì •ì§€ë°ì´í„°.csv\")\n",
    "stop_df[\"label\"] = \"stop\"\n",
    "\n",
    "# ë³‘í•©\n",
    "df = pd.concat([walk_df, run_df, stop_df], ignore_index=True)\n",
    "\n",
    "# ì‚¬ìš©í•  ì»¬ëŸ¼ ì§€ì •\n",
    "feature_cols = [\n",
    "    'Linear Acceleration x (m/s^2)',\n",
    "    'Linear Acceleration y (m/s^2)',\n",
    "    'Linear Acceleration z (m/s^2)'\n",
    "]\n",
    "\n",
    "# 2. ì „ì²˜ë¦¬: ìˆ˜ì¹˜í˜• ë³€í™˜ â†’ ê²°ì¸¡ì¹˜ ì œê±° â†’ ì´ìƒì¹˜ ì œê±°\n",
    "for col in feature_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df_clean = df.dropna(subset=feature_cols)\n",
    "z_scores = np.abs(zscore(df_clean[feature_cols]))\n",
    "df_clean = df_clean[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# 3. ì‹œê°í™” (pairplot)\n",
    "sns.pairplot(df_clean[feature_cols + ['label']], hue='label', diag_kind=\"hist\")\n",
    "plt.suptitle(\"ì„¼ì„œ ë°ì´í„° ìƒíƒœë³„ ë¶„í¬ (ì „ì²˜ë¦¬ í›„)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# 4. í•™ìŠµ ë°ì´í„° êµ¬ì„±\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 5. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    # 'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')  # yë¥¼ ìˆ«ìë¡œ ë°”ê¿”ì•¼ ì‚¬ìš© ê°€ëŠ¥\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='macro'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='macro'),\n",
    "        'F1 Score': f1_score(y_test, y_pred, average='macro')\n",
    "    })\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[\"walk\", \"run\", \"stop\"])\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=[\"walk\", \"run\", \"stop\"], yticklabels=[\"walk\", \"run\", \"stop\"])\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 6. ì„±ëŠ¥ ë¹„êµí‘œ ì¶œë ¥\n",
    "results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)\n",
    "print(\"\\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d97a3",
   "metadata": {},
   "source": [
    "## Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# í˜ì´ì§€ ì„¤ì •\n",
    "st.set_page_config(page_title=\"Sensor Activity Classifier\", layout=\"wide\")\n",
    "st.title(\"ğŸ“Š Sensor Activity Classification App\")\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "ì´ ì•±ì€ ê°€ì†ë„ ì„¼ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ëŒì˜ ìƒíƒœ (ê±·ê¸°, ë›°ê¸°, ì •ì§€)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\"\"\")\n",
    "\n",
    "# ë°ì´í„° ì—…ë¡œë“œ\n",
    "uploaded_walk = st.file_uploader(\"ê±·ê¸° ë°ì´í„° ì—…ë¡œë“œ\", type=\"csv\")\n",
    "uploaded_run = st.file_uploader(\"ë›°ê¸° ë°ì´í„° ì—…ë¡œë“œ\", type=\"csv\")\n",
    "uploaded_stop = st.file_uploader(\"ì •ì§€ ë°ì´í„° ì—…ë¡œë“œ\", type=\"csv\")\n",
    "\n",
    "if uploaded_walk and uploaded_run and uploaded_stop:\n",
    "    # CSV ì½ê¸°\n",
    "    walk_df = pd.read_csv(uploaded_walk)\n",
    "    walk_df['label'] = 'walk'\n",
    "    run_df = pd.read_csv(uploaded_run)\n",
    "    run_df['label'] = 'run'\n",
    "    stop_df = pd.read_csv(uploaded_stop)\n",
    "    stop_df['label'] = 'stop'\n",
    "\n",
    "    # ë³‘í•©\n",
    "    df = pd.concat([walk_df, run_df, stop_df], ignore_index=True)\n",
    "\n",
    "    # ì „ì²˜ë¦¬\n",
    "    feature_cols = [\n",
    "        'Linear Acceleration x (m/s^2)',\n",
    "        'Linear Acceleration y (m/s^2)',\n",
    "        'Linear Acceleration z (m/s^2)'\n",
    "    ]\n",
    "    for col in feature_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    df = df.dropna(subset=feature_cols)\n",
    "\n",
    "    # ì´ìƒì¹˜ ì œê±°\n",
    "    from scipy.stats import zscore\n",
    "    z_scores = np.abs(zscore(df[feature_cols]))\n",
    "    df = df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "    # ì‹œê°í™”\n",
    "    st.subheader(\"ğŸ“ˆ Feature Pairplot\")\n",
    "    fig = sns.pairplot(df[feature_cols + ['label']], hue='label', diag_kind=\"hist\")\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    # í•™ìŠµ ì¤€ë¹„\n",
    "    X = df[feature_cols]\n",
    "    y = df['label']\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # ëª¨ë¸\n",
    "    models = {\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    st.subheader(\"ğŸ“Š Model Performance\")\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='macro')\n",
    "        rec = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "\n",
    "        st.markdown(f\"### {name} Confusion Matrix\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        fig_cm, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=le.classes_, yticklabels=le.classes_, ax=ax)\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"True\")\n",
    "        st.pyplot(fig_cm)\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)\n",
    "    st.subheader(\"ğŸ Summary Table\")\n",
    "    st.dataframe(results_df, use_container_width=True)\n",
    "\n",
    "else:\n",
    "    st.info(\"ëª¨ë“  ì„¼ì„œ CSV íŒŒì¼(ê±·ê¸°, ë›°ê¸°, ì •ì§€)ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
