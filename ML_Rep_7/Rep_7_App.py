import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier

st.set_page_config(layout="wide")
st.title("ğŸ‘· ê³ ì†Œ ì‘ì—…ì ìƒíƒœ ë¶„ë¥˜ ML ì‹œìŠ¤í…œ")
st.write("ì„¼ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ì—¬ëŸ¬ ML ëª¨ë¸ì„ í‰ê°€í•˜ê³  ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# íŒŒì¼ ì—…ë¡œë“œ
train_file = st.file_uploader("ğŸ“¥ í•™ìŠµìš© CSV ì—…ë¡œë“œ (x, y, z, label í¬í•¨)", type="csv")
test_file = st.file_uploader("ğŸ“¥ ì˜ˆì¸¡ìš© CSV ì—…ë¡œë“œ (x, y, z)", type="csv")

if train_file:
    df = pd.read_csv(train_file)

    # ë°ì´í„° í™•ì¸
    if not {'x', 'y', 'z', 'label'}.issubset(df.columns):
        st.error("âŒ í•™ìŠµ ë°ì´í„°ì—ëŠ” 'x', 'y', 'z', 'label' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        # ì „ì²˜ë¦¬
        X = df[['x', 'y', 'z']]
        y = df['label']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # ëª¨ë¸ ì •ì˜
        models = {
            'KNN': KNeighborsClassifier(),
            'Logistic Regression': LogisticRegression(max_iter=1000),
            'Decision Tree': DecisionTreeClassifier(),
            'Random Forest': RandomForestClassifier(),
            'Gradient Boosting': GradientBoostingClassifier(),
            'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
        }

        results = []
        predictions_dict = {}

        st.subheader("ğŸ“Š ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ê²°ê³¼")

        for name, model in models.items():
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            predictions_dict[name] = model  # ì €ì¥í•´ë‘ê¸°

            acc = accuracy_score(y_test, y_pred)
            prec = precision_score(y_test, y_pred, average='macro', zero_division=0)
            rec = recall_score(y_test, y_pred, average='macro', zero_division=0)
            f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)

            results.append({
                'Model': name,
                'Accuracy': acc,
                'Precision': prec,
                'Recall': rec,
                'F1 Score': f1
            })

        results_df = pd.DataFrame(results).sort_values(by='F1 Score', ascending=False)
        st.dataframe(results_df.style.highlight_max(axis=0))

        # Confusion Matrix ì‹œê°í™”
        st.subheader("ğŸ“‰ Confusion Matrix")
        selected_for_cm = st.selectbox("ğŸ” Confusion Matrix ë³´ê¸°: ëª¨ë¸ ì„ íƒ", list(models.keys()))
        model = models[selected_for_cm]
        y_pred = model.predict(X_test_scaled)
        cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt='d', xticklabels=np.unique(y), yticklabels=np.unique(y), ax=ax)
        plt.xlabel("Predicted")
        plt.ylabel("True")
        plt.title(f"{selected_for_cm} - Confusion Matrix")
        st.pyplot(fig)

        # ì˜ˆì¸¡ìš© ë°ì´í„° ì²˜ë¦¬
        if test_file:
            test_df = pd.read_csv(test_file)
            if not {'x', 'y', 'z'}.issubset(test_df.columns):
                st.error("âŒ ì˜ˆì¸¡ìš© CSVì—ëŠ” 'x', 'y', 'z' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                st.subheader("ğŸ” ì˜ˆì¸¡ ì‹¤í–‰")
                selected_model = st.selectbox("ğŸ“Œ ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ", results_df['Model'].tolist())
                best_model = predictions_dict[selected_model]
                X_input = test_df[['x', 'y', 'z']]
                X_scaled = scaler.transform(X_input)
                pred_labels = best_model.predict(X_scaled)
                test_df['ì˜ˆì¸¡ëœ ìƒíƒœ'] = pred_labels

                st.success("âœ… ì˜ˆì¸¡ ì™„ë£Œ")
                st.dataframe(test_df)

                st.write("ğŸ“ˆ ìƒíƒœ ë¶„í¬")
                st.bar_chart(test_df['ì˜ˆì¸¡ëœ ìƒíƒœ'].value_counts())

